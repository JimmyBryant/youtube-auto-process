import asyncio
import logging
import shutil
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import uuid

from .task_manager import TaskManager
from .models import TaskStatus, TaskStage, StageStatus, TaskModel, ProcessingType
from src.modules.video_downloader import download_video
from src.modules.transcriber import AudioTranscriber
import os
from src.modules.translation_service import TranslationService
from src.modules.subtitle_splitting import split_srt_file
from src.modules.comment_processor import fetch_comments, process_comments
from src.modules.video_editor import edit_video
from src.modules.publisher import VideoPublisher  # ä¿®æ”¹ä¸ºå¯¼å…¥ç±»

logger = logging.getLogger('task_scheduler')

class TaskScheduler:
    """å¢å¼ºç‰ˆä»»åŠ¡è°ƒåº¦å™¨ï¼Œæ”¯æŒæ–­ç‚¹ç»­åšå’Œè¯¦ç»†é˜¶æ®µç®¡ç†"""
    
    def __init__(self, 
                 max_concurrent_tasks: int = 3,
                 temp_base_dir: str = "/tmp/video_processing",
                 cookie_file: Path = None):
        try:
            self.task_manager = TaskManager()
            self.max_concurrent_tasks = max_concurrent_tasks
            self.active_tasks: Dict[str, asyncio.Task] = {}
            self._stop_event = asyncio.Event()
            self.temp_base_dir = Path(temp_base_dir)
            self.temp_base_dir.mkdir(parents=True, exist_ok=True)
            self.cookie_file = cookie_file
            # é˜¶æ®µå¤„ç†å™¨æ˜ å°„
            self.stage_handlers = {
                TaskStage.DOWNLOADING: lambda task, task_dir: self._handle_downloading(task, task_dir, self.cookie_file),
                TaskStage.TRANSCRIBING: lambda task, task_dir: self._handle_transcribing(task),
                TaskStage.TRANSLATING: lambda task, task_dir: self._handle_translating(task),
                TaskStage.SUBTITLE_SPLITTING: lambda task, task_dir: self._handle_subtitle_splitting(task),
                # TaskStage.COMMENT_FETCHING: lambda task, task_dir: self._handle_comment_fetching(task),
                # TaskStage.COMMENT_PROCESSING: lambda task, task_dir: self._handle_comment_processing(task),
                # TaskStage.SYNTHESIZING: lambda task, task_dir: self._handle_synthesizing(task),
                # TaskStage.PUBLISHING: lambda task, task_dir: self._handle_publishing(task),
            }
            
            # é˜¶æ®µæ‰§è¡Œé¡ºåº
            self.stage_sequence = [
                TaskStage.DOWNLOADING,
                TaskStage.TRANSCRIBING,
                TaskStage.TRANSLATING,
                TaskStage.SUBTITLE_SPLITTING,
                # TaskStage.COMMENT_FETCHING,
                # TaskStage.COMMENT_PROCESSING,
                # TaskStage.SYNTHESIZING,
                # TaskStage.PUBLISHING
            ]
            # æ£€æŸ¥é˜¶æ®µå¤„ç†å™¨æ˜¯å¦é…ç½®æ­£ç¡®
            if not hasattr(self, 'stage_handlers'):
                raise RuntimeError("stage_handlers æœªæ­£ç¡®åˆå§‹åŒ–")
            if not hasattr(self, 'stage_sequence'):
                raise RuntimeError("stage_sequence æœªæ­£ç¡®åˆå§‹åŒ–")    
        except Exception as e:
            logger.error(f"è°ƒåº¦å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    async def start(self):
        """å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨ä¸»å¾ªç¯ï¼Œæ”¯æŒ failed ä»»åŠ¡æ–­ç‚¹ç»­åšï¼Œ3æ¬¡å¤±è´¥åéœ€æ‰‹åŠ¨æ¢å¤ï¼Œè‡ªåŠ¨æ£€æµ‹åƒµå°¸é˜¶æ®µ"""
        logger.info("ğŸš€ Starting task scheduler main loop")
        ZOMBIE_TIMEOUT = 30 * 60  # 30åˆ†é’Ÿæœªæ›´æ–°å³è§†ä¸ºåƒµå°¸ä»»åŠ¡ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
        while not self._stop_event.is_set():
            try:
                # è·å–å¾…å¤„ç†å’Œå¤±è´¥çš„ä»»åŠ¡
                tasks = await self.task_manager.list_tasks(limit=100)
                now = datetime.now(timezone.utc)
                # è‡ªåŠ¨æ£€æµ‹å¹¶æ¢å¤åƒµå°¸é˜¶æ®µï¼ˆprocessingçŠ¶æ€é•¿æ—¶é—´æœªæ›´æ–°ï¼‰
                for task in tasks:
                    for stage, progress in (task.stage_progress or {}).items():
                        if getattr(progress, 'status', None) == 'processing':
                            updated_at = getattr(progress, 'updated_at', None)
                            if updated_at and (now - updated_at).total_seconds() > ZOMBIE_TIMEOUT:
                                logger.warning(f"æ£€æµ‹åˆ°åƒµå°¸é˜¶æ®µ: ä»»åŠ¡{task.id} é˜¶æ®µ{stage}ï¼Œè‡ªåŠ¨é‡ç½®ä¸ºpending")
                                await self.task_manager.update_stage_status(
                                    task_id=task.id,
                                    stage=stage,
                                    status='pending',
                                    error='è‡ªåŠ¨æ£€æµ‹åˆ°åƒµå°¸é˜¶æ®µï¼Œå·²é‡ç½®ä¸ºpending'
                                )
                # åªè‡ªåŠ¨å¤„ç†æœªæ ‡è®° manual_resume çš„ä»»åŠ¡
                candidate_tasks = [t for t in tasks if t.status in [TaskStatus.PENDING, TaskStatus.FAILED] and not getattr(t, 'manual_resume', False)]
                if len(self.active_tasks) < self.max_concurrent_tasks and candidate_tasks:
                    candidate_tasks.sort(key=lambda t: t.priority, reverse=True)
                    for task in candidate_tasks[:self.max_concurrent_tasks - len(self.active_tasks)]:
                        task_id = task.id
                        if task_id not in self.active_tasks:
                            logger.info(f"â–¶ï¸ Starting processing for task {task_id}")
                            self.active_tasks[task_id] = asyncio.create_task(self._process_task(task))
                            self.active_tasks[task_id].add_done_callback(
                                lambda t, tid=task_id: self._task_done_callback(t, tid)
                            )
                await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"âš ï¸ Scheduler loop error: {str(e)}")
                await asyncio.sleep(5)
    async def _process_task(self, task: TaskModel):
        task_dir = None
        """å¤„ç†å•ä¸ªä»»åŠ¡ï¼Œæ”¯æŒæ–­ç‚¹ç»­åšï¼Œé˜¶æ®µå¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡ï¼Œ3æ¬¡å¤±è´¥åéœ€æ‰‹åŠ¨æ¢å¤"""
        try:
            # åˆ›å»ºå”¯ä¸€ä¸´æ—¶ç›®å½•
            task_dir = self.temp_base_dir / f"task_{task.id}_{uuid.uuid4().hex[:6]}"
            task_dir.mkdir(exist_ok=True)
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
            await self.task_manager.update_task_status(task.id, TaskStatus.PROCESSING)

            for stage in self.stage_sequence:
                # æ¯æ¬¡å¾ªç¯éƒ½åˆ·æ–°æœ€æ–° task çŠ¶æ€ï¼Œç¡®ä¿ä¾èµ–çš„é˜¶æ®µçŠ¶æ€æ˜¯æœ€æ–°çš„
                task = await self.task_manager.get_task_by_id(task.id)
                stage_progress = task.stage_progress.get(stage)
                if stage_progress and stage_progress.status == StageStatus.COMPLETED:
                    logger.info(f"â© è·³è¿‡å·²å®Œæˆé˜¶æ®µ {stage} for task {task.id}")
                    continue
                max_retries = 3
                for attempt in range(1, max_retries + 1):
                    success, outputs = await self.stage_handlers[stage](task, task_dir)
                    if success:
                        await self.task_manager.update_stage_status(
                            task_id=task.id,
                            stage=stage,
                            status=StageStatus.COMPLETED,
                            output_files=outputs
                        )
                        break
                    else:
                        logger.warning(f"é˜¶æ®µ {stage} ç¬¬ {attempt} æ¬¡æ‰§è¡Œå¤±è´¥ï¼Œä»»åŠ¡ID: {task.id}")
                        if attempt < max_retries:
                            await asyncio.sleep(3)
                else:
                    logger.error(f"é˜¶æ®µ {stage} è¿ç»­3æ¬¡å¤±è´¥ï¼Œä»»åŠ¡ID: {task.id}ï¼Œä»»åŠ¡ç»ˆæ­¢")
                    # æ ‡è®°ä»»åŠ¡ä¸ºFAILEDå¹¶åŠ manual_resume
                    await self.task_manager.update_task_status(task.id, TaskStatus.FAILED, extra={"manual_resume": True})
                    return

            await self.task_manager.update_task_status(task.id, TaskStatus.COMPLETED)
            logger.info(f"ğŸ‰ Task {task.id} completed successfully")

        except Exception as e:
            logger.error(f"âŒ Task {task.id} failed: {str(e)}")
            await self.task_manager.update_task_status(task.id, TaskStatus.FAILED, error=str(e), extra={"manual_resume": True})
        finally:
            if task_dir and task.status in {TaskStatus.COMPLETED, TaskStatus.FAILED}:
                await self._cleanup_task_files(task_dir)

    async def monitor_status(self):
        """ç›‘æ§ä»»åŠ¡çŠ¶æ€"""
        logger.info("ğŸ“Š Starting task status monitor")
        while not self._stop_event.is_set():
            try:
                # è¿™é‡Œå¯ä»¥æ·»åŠ çŠ¶æ€ç›‘æ§é€»è¾‘
                # ä¾‹å¦‚ï¼šè®°å½•æ´»è·ƒä»»åŠ¡æ•°ã€æ£€æŸ¥é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ç­‰
                await asyncio.sleep(10)
            except Exception as e:
                logger.error(f"âš ï¸ Status monitor error: {str(e)}")
                await asyncio.sleep(30) 
    async def _handle_downloading(self, task: TaskModel, task_dir: str, cookie_file: Path = None) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†è§†é¢‘ä¸‹è½½é˜¶æ®µ"""
        logger.info(f"ğŸ“¥ğŸ“¥ Handling downloading for task {task.id}")
        
        stage_progress = task.stage_progress.get(TaskStage.DOWNLOADING)
        if stage_progress is not None and stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed downloading for task {task.id}")
            return True, stage_progress.output_files
    
        
        try:
            # å¼€å§‹é˜¶æ®µ
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.DOWNLOADING,
                status=StageStatus.PROCESSING
            )
            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ cookie_fileï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶
            import os
            final_cookie_file = cookie_file
            if final_cookie_file is None:
                cookie_path = os.getenv('YT_COOKIE_PATH')
                if not cookie_path:
                    from dotenv import dotenv_values
                    config_path = Path(__file__).parent.parent.parent / 'config' / 'dev.env'
                    config = dotenv_values(config_path)
                    cookie_path = config.get('YT_COOKIE_PATH')
                final_cookie_file = Path(cookie_path) if cookie_path else None
            # ä¸‹è½½è§†é¢‘å’Œå°é¢
            video_path, thumbnail_path = await download_video(task.video_url, task_dir, final_cookie_file)
            
            outputs = {
                "video_path": str(video_path),
                "thumbnail_path": str(thumbnail_path)
            }
            
            return True, outputs
        except Exception as e:
            logger.error(f"âŒâŒ Download failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.DOWNLOADING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    async def _handle_transcribing(self, task: TaskModel) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†å­—å¹•ç”Ÿæˆé˜¶æ®µï¼ˆwhisperx mediumï¼‰"""
        logger.info(f"ğŸ”¤ğŸ”¤ Handling transcribing for task {task.id}")
        stage_progress = task.stage_progress.get(TaskStage.TRANSCRIBING)
        if stage_progress is not None and stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed transcribing for task {task.id}")
            return True, stage_progress.output_files
        # æ£€æŸ¥å‰ç½®é˜¶æ®µæ˜¯å¦å®Œæˆ
        download_progress = task.stage_progress.get(TaskStage.DOWNLOADING)
        if download_progress is None or download_progress.status != StageStatus.COMPLETED:
            raise RuntimeError(f"Download not completed for task {task.id}, can't transcribe")
        try:
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.TRANSCRIBING,
                status=StageStatus.PROCESSING
            )
            video_path = Path(download_progress.output_files["video_path"])
            transcriber = AudioTranscriber(model_size="medium", device="cpu")
            srt_path = await transcriber.transcribe(task.id, video_path)
            outputs = {"subtitle_path": str(srt_path)} if srt_path else {}
            return (srt_path is not None), outputs
        except Exception as e:
            logger.error(f"âŒâŒ Transcribing failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.TRANSCRIBING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    async def _handle_translating(self, task: TaskModel) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†å­—å¹•ç¿»è¯‘é˜¶æ®µï¼Œæ”¯æŒå¤šå®¶å¤§è¯­è¨€æ¨¡å‹APIï¼Œç›®æ ‡è¯­è¨€å’ŒAPI KEYé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼Œè‡ªåŠ¨åˆ†æ®µç¿»è¯‘"""
        logger.info(f"ğŸŒğŸŒ Handling translating for task {task.id}")

        stage_progress = task.stage_progress.get(TaskStage.TRANSLATING)
        if stage_progress and stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed translating for task {task.id}")
            return True, stage_progress.output_files

        # æ£€æŸ¥å‰ç½®é˜¶æ®µæ˜¯å¦å®Œæˆ
        transcribe_progress = task.stage_progress.get(TaskStage.TRANSCRIBING)
        if not transcribe_progress or transcribe_progress.status != StageStatus.COMPLETED:
            raise RuntimeError(f"Transcribing not completed for task {task.id}, can't translate")

        try:
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.TRANSLATING,
                status=StageStatus.PROCESSING
            )

            subtitle_path = Path(transcribe_progress.output_files["subtitle_path"])
            # ä½¿ç”¨ TranslationService ç±»è¿›è¡Œç¿»è¯‘
            translation_service = TranslationService()
            translated_srt_path = await translation_service.translate_subtitle(subtitle_path)
            outputs = {"translated_subtitle_path": str(translated_srt_path)}
            return True, outputs
        except Exception as e:
            logger.error(f"âŒâŒ Translating failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.TRANSLATING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    async def _handle_subtitle_splitting(self, task: TaskModel) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†å­—å¹•åˆ†å‰²é˜¶æ®µï¼Œç¡®ä¿åŸå§‹å’Œç¿»è¯‘åçš„ SRT æ¯è¡Œä¸è¶…é•¿ï¼Œè¾“å‡ºæ–° SRT æ–‡ä»¶è·¯å¾„"""
        logger.info(f"âœ‚ï¸âœ‚ï¸ Handling subtitle splitting for task {task.id}")
        stage_progress = task.stage_progress.get(TaskStage.SUBTITLE_SPLITTING)
        if stage_progress and stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed subtitle splitting for task {task.id}")
            return True, stage_progress.output_files

        # æ£€æŸ¥å‰ç½®é˜¶æ®µ
        transcribe_progress = task.stage_progress.get(TaskStage.TRANSCRIBING)
        translate_progress = task.stage_progress.get(TaskStage.TRANSLATING)
        if not transcribe_progress or transcribe_progress.status != StageStatus.COMPLETED:
            raise RuntimeError(f"Transcribing not completed for task {task.id}, can't split subtitles")
        if not translate_progress or translate_progress.status != StageStatus.COMPLETED:
            raise RuntimeError(f"Translating not completed for task {task.id}, can't split subtitles")

        try:
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.SUBTITLE_SPLITTING,
                status=StageStatus.PROCESSING
            )

            orig_srt_path = Path(transcribe_progress.output_files["subtitle_path"])
            trans_srt_path = Path(translate_progress.output_files["translated_subtitle_path"])

            # è¾“å‡ºæ–°æ–‡ä»¶å
            orig_split_path = orig_srt_path.parent / (orig_srt_path.stem + ".split.srt")
            trans_split_path = trans_srt_path.parent / (trans_srt_path.stem + ".split.srt")

            # åˆ†å‰²åŸæ–‡å’Œè¯‘æ–‡ SRT
            split_srt_file(str(orig_srt_path), str(orig_split_path), max_line_length=32)
            split_srt_file(str(trans_srt_path), str(trans_split_path), max_line_length=32)

            outputs = {
                "split_subtitle_path": str(orig_split_path),
                "split_translated_subtitle_path": str(trans_split_path)
            }
            return True, outputs
        except Exception as e:
            logger.error(f"âŒâŒ Subtitle splitting failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.SUBTITLE_SPLITTING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    async def _handle_comment_fetching(self, task: TaskModel) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†è¯„è®ºè·å–é˜¶æ®µ"""
        logger.info(f"ğŸ’¬ğŸ’¬ Handling comment fetching for task {task.id}")
        
        stage_progress = task.stage_progress.get(TaskStage.COMMENT_FETCHING)
        if stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed comment fetching for task {task.id}")
            return True, stage_progress.output_files
        
        try:
            # å¼€å§‹é˜¶æ®µ
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.COMMENT_FETCHING,
                status=StageStatus.PROCESSING
            )
            
            # è·å–è¯„è®º
            task_dir = Path(task.temp_dir)
            comments_file = await fetch_comments(task.video_url, task_dir)
            
            # è¿”å›è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            outputs = {
                "comments_file": str(comments_file)
            }
            
            return True, outputs
        except Exception as e:
            logger.error(f"âŒâŒ Comment fetching failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.COMMENT_FETCHING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    async def _handle_comment_processing(self, task: TaskModel) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†è¯„è®ºå¤„ç†é˜¶æ®µ"""
        logger.info(f"ğŸ–¼ğŸ–¼ Handling comment processing for task {task.id}")
        
        stage_progress = task.stage_progress.get(TaskStage.COMMENT_PROCESSING)
        if stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed comment processing for task {task.id}")
            return True, stage_progress.output_files
        
        # æ£€æŸ¥å‰ç½®é˜¶æ®µæ˜¯å¦å®Œæˆ
        fetch_progress = task.stage_progress.get(TaskStage.COMMENT_FETCHING)
        if fetch_progress.status != StageStatus.COMPLETED:
            raise RuntimeError(f"Comment fetching not completed for task {task.id}, can't process")
        
        try:
            # å¼€å§‹é˜¶æ®µ
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.COMMENT_PROCESSING,
                status=StageStatus.PROCESSING
            )
            
            # è·å–è¯„è®ºæ–‡ä»¶è·¯å¾„
            comments_file = Path(fetch_progress.output_files["comments_file"])
            
            # å¤„ç†è¯„è®ºå¹¶ç”Ÿæˆå›¾ç‰‡
            task_dir = Path(task.temp_dir)
            comment_images = await process_comments(comments_file, task_dir)
            
            # è¿”å›è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            outputs = {
                "comment_images": [str(img) for img in comment_images]
            }
            
            return True, outputs
        except Exception as e:
            logger.error(f"âŒâŒ Comment processing failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.COMMENT_PROCESSING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    async def _handle_synthesizing(self, task: TaskModel) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†è§†é¢‘åˆæˆé˜¶æ®µ"""
        logger.info(f"ğŸ¬ğŸ¬ Handling synthesizing for task {task.id}")
        
        stage_progress = task.stage_progress.get(TaskStage.SYNTHESIZING)
        if stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed synthesizing for task {task.id}")
            return True, stage_progress.output_files
        
        # æ£€æŸ¥å‰ç½®é˜¶æ®µæ˜¯å¦å®Œæˆ
        required_stages = [
            (TaskStage.DOWNLOADING, "Downloading"),
            (TaskStage.TRANSLATING, "Translating"),
            (TaskStage.COMMENT_PROCESSING, "Comment processing")
        ]
        
        for stage, name in required_stages:
            progress = task.stage_progress.get(stage)
            if progress.status != StageStatus.COMPLETED:
                raise RuntimeError(f"{name} not completed for task {task.id}, can't synthesize")
        
        try:
            # å¼€å§‹é˜¶æ®µ
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.SYNTHESIZING,
                status=StageStatus.PROCESSING
            )
            
            # è·å–æ‰€éœ€æ–‡ä»¶è·¯å¾„
            download_progress = task.stage_progress.get(TaskStage.DOWNLOADING)
            translate_progress = task.stage_progress.get(TaskStage.TRANSLATING)
            comment_progress = task.stage_progress.get(TaskStage.COMMENT_PROCESSING)
            
            video_path = Path(download_progress.output_files["video_path"])
            translated_subtitle_path = Path(translate_progress.output_files["translated_subtitle_path"])
            comment_images = [Path(img) for img in comment_progress.output_files["comment_images"]]
            
            # åˆæˆè§†é¢‘
            task_dir = Path(task.temp_dir)
            output_path = await edit_video(
                video_path=video_path,
                subtitle_path=translated_subtitle_path,
                comment_images=comment_images,
                output_dir=task_dir
            )
            
            # æ›´æ–°ä»»åŠ¡è¾“å‡ºæ–‡ä»¶è·¯å¾„
            await self.task_manager.save_task(task)
            
            # è¿”å›è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            outputs = {
                "output_path": str(output_path)
            }
            
            return True, outputs
        except Exception as e:
            logger.error(f"âŒâŒ Synthesizing failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.SYNTHESIZING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    async def _handle_publishing(self, task: TaskModel) -> Tuple[bool, Dict[str, str]]:
        """å¤„ç†è§†é¢‘å‘å¸ƒé˜¶æ®µ"""
        logger.info(f"ğŸ“¤ğŸ“¤ Handling publishing for task {task.id}")
        
        stage_progress = task.stage_progress.get(TaskStage.PUBLISHING)
        if stage_progress.status == StageStatus.COMPLETED:
            logger.info(f"â©â©â© Skipping already completed publishing for task {task.id}")
            return True, stage_progress.output_files
        
        # æ£€æŸ¥å‰ç½®é˜¶æ®µæ˜¯å¦å®Œæˆ
        synthesize_progress = task.stage_progress.get(TaskStage.SYNTHESIZING)
        if synthesize_progress.status != StageStatus.COMPLETED:
            raise RuntimeError(f"Synthesizing not completed for task {task.id}, can't publish")
        
        try:
            # å¼€å§‹é˜¶æ®µ
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.PUBLISHING,
                status=StageStatus.PROCESSING
            )
            
            # è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_path = Path(synthesize_progress.output_files["output_path"])
            
            # å‘å¸ƒè§†é¢‘
            publish_result = await publish_video(output_path, task.metadata)
            
            # è¿”å›å‘å¸ƒç»“æœ
            outputs = {
                "publish_result": publish_result
            }
            
            return True, outputs
        except Exception as e:
            logger.error(f"âŒâŒ Publishing failed for task {task.id}: {str(e)}")
            await self.task_manager.update_stage_status(
                task_id=task.id,
                stage=TaskStage.PUBLISHING,
                status=StageStatus.FAILED,
                error=str(e)
            )
            return False, {}

    # ... (ä¿ç•™ä¹‹å‰çš„ _task_done_callback, _cleanup, _cleanup_task_files æ–¹æ³•)
            
    def _task_done_callback(self, task: asyncio.Task, task_id: str) -> None:
        """ä»»åŠ¡å®Œæˆå›è°ƒ"""
        self.active_tasks.pop(task_id, None)
        if task.exception():
            logger.error(f"âŒâŒ Task {task_id} raised an exception", exc_info=task.exception())
            
    async def _cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ğŸ§¹ Cleaning up resources...")
        for task_id, task in self.active_tasks.items():
            if not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    logger.debug(f"Task {task_id} cancelled")
                    
        self.active_tasks.clear()
        logger.info("âœ… Task scheduler cleanup completed")
        
    async def _cleanup_task_files(self, task_dir: Path):
        """æ¸…ç†ä»»åŠ¡ä¸´æ—¶æ–‡ä»¶"""
        try:
            if task_dir.exists() and task_dir.is_dir():
                shutil.rmtree(task_dir)
                logger.debug(f"ğŸ§¹ğŸ§¹ Cleaned up files for task: {task_dir.name}")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to clean up task files: {str(e)}")